<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>Fitting Hyperbolic Discounting Functions &#8211; Alexander Fengler</title>
<meta name="description" content="Step by Step Guide">
<meta name="keywords" content="Intertemporal Discounting, Likelihood-fitting, Choice-Data">

  

<!-- Twitter Cards -->
<meta name="twitter:title" content="Fitting Hyperbolic Discounting Functions">
<meta name="twitter:description" content="Step by Step Guide">
<meta name="twitter:site" content="@UniFersAlex">
<meta name="twitter:creator" content="@UniFersAlex">

<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://AlexanderFengler.github.io/images/bio-photo.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="Fitting Hyperbolic Discounting Functions">
<meta property="og:description" content="Step by Step Guide">
<meta property="og:url" content="http://AlexanderFengler.github.io/neuroeconomics/K-Estimation/">
<meta property="og:site_name" content="Alexander Fengler">





<link rel="canonical" href="http://AlexanderFengler.github.io/neuroeconomics/K-Estimation/">
<link href="http://AlexanderFengler.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Alexander Fengler Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://AlexanderFengler.github.io/assets/css/main.css">
<!-- Webfonts -->
<script src="//use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://AlexanderFengler.github.io/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://AlexanderFengler.github.io/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://AlexanderFengler.github.io/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>

<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://AlexanderFengler.github.io/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://AlexanderFengler.github.io/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://AlexanderFengler.github.io/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://AlexanderFengler.github.io/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://AlexanderFengler.github.io/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://AlexanderFengler.github.io/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		        
		    
		    <li><a href="http://AlexanderFengler.github.io/about/" >About Me</a></li>
		  
		    
		        
		    
		    <li><a href="http://AlexanderFengler.github.io/statistics/" >Statistics</a></li>
		  
		    
		        
		    
		    <li><a href="http://AlexanderFengler.github.io/neuroeconomics/" >Neuroeconomics</a></li>
		  
		    
		        
		    
		    <li><a href="http://AlexanderFengler.github.io/research/" >Research</a></li>
		  
		    
		        
		    
		    <li><a href="http://AlexanderFengler.github.io/code/" >Code</a></li>
		  
		    
		        
		    
		    <li><a href="http://AlexanderFengler.github.io/resources/" >Resources</a></li>
		  
		    
		        
		    
		    <li><a href="http://AlexanderFengler.github.io/search/" >Search</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

<header class="masthead">
	<div class="wrap">
        
    		<a href="http://AlexanderFengler.github.io/" class="site-logo" rel="home" title="Alexander Fengler"><img src="http://AlexanderFengler.github.io/images/bio-photo.png" width="200" height="200" alt="Alexander Fengler logo" class="animated fadeInUp"></a>
        
        <h1 class="site-title animated fadeIn"><a href="http://AlexanderFengler.github.io/">Alexander Fengler</a></h1>
		<h2 class="site-description animated fadeIn" itemprop="description">Neuroeconomist</h2>
	</div>
</header><!-- /.masthead -->

<div class="js-menu-screen menu-screen"></div>

<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        <span class="entry-tags"><a href="http://AlexanderFengler.github.io/tags/#Intertemporal Discounting" title="Pages tagged Intertemporal Discounting">Intertemporal Discounting</a>&nbsp;&bull;&nbsp;<a href="http://AlexanderFengler.github.io/tags/#Likelihood-fitting" title="Pages tagged Likelihood-fitting">Likelihood-fitting</a>&nbsp;&bull;&nbsp;<a href="http://AlexanderFengler.github.io/tags/#Choice-Data" title="Pages tagged Choice-Data">Choice-Data</a></span>
        
          <h1 class="entry-title">Fitting Hyperbolic Discounting Functions</h1>
        
      </header>
      <footer class="entry-meta">
        
          
        
          <img src="http://AlexanderFengler.github.io/images/af_authoravatar.jpg" class="bio-photo" alt="Alexander Fengler bio photo"></a>
        
        <span class="author vcard">By <span class="fn">Alexander Fengler</span></span>
        <span class="entry-date date published"><time datetime="2015-02-07T00:00:00-08:00"><i class="fa fa-calendar-o"></i> February 07, 2015</time></span>
        
        
        <span class="social-share-twitter">
  <a href="https://twitter.com/intent/tweet?hashtags=IntertemporalDiscounting,Likelihood-fitting,Choice-Data&amp;text=Fitting%20Hyperbolic%20Discounting%20Functions&amp;url=http://AlexanderFengler.github.io/neuroeconomics/K-Estimation/&amp;via=UniFersAlex" title="Share on Twitter" itemprop="Twitter"><i class="fa fa-twitter-square"></i> Tweet</a>
</span>
<span class="social-share-facebook">
  <a href="https://www.facebook.com/sharer/sharer.php?u=http://AlexanderFengler.github.io/neuroeconomics/K-Estimation/" title="Share on Facebook" itemprop="Facebook"><i class="fa fa-facebook-square"></i> Like</a>
</span>
<span class="social-share-googleplus">
  <a href="https://plus.google.com/share?url=http://AlexanderFengler.github.io/neuroeconomics/K-Estimation/" title="Share on Google Plus" itemprop="GooglePlus"><i class="fa fa-google-plus-square"></i> +1</a>
</span>
<!-- /.social-share -->
        
      </footer>
      <div class="entry-content">
        <h1 id="tutorial-on-how-to-estimate-individual-k-values-hyperbolic-discounting">Tutorial on how to estimate individual k-values (Hyperbolic Discounting)</h1>

<p>In the following I will walk you through the complete procedure necessary to estimate the individual discounting parameter when 
assuming hyperbolic discounting. Once established, the procedure applies analogously to other base functions commonly used to describe human intertemporal decision making (namely exponential discounting, alpha-beta discounting). We closely follow the approach taken by Chabris and Laibson (2008)<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup> in their paper <em>Individiual laboratory-measured discount rates predict field behavior</em> published in the <em>Journal of Risk and Uncertainty</em>.</p>

<h2 id="outline-of-the-general-procedure">Outline of the general procedure</h2>

<p>The hyperbolic discounting function we use in the following is captured by the following term.</p>

<p><cite> D(t) = 1 / (1 + k*t) </cite></p>

<p>This equation describes the value assigned to a monetary reward, dependent on the associated time-delay (in arbitrary units, may be days, weeks, month, years). If an individual assignes value (utility) to rewards according to this function, it transforms every possible combination of delay and payoff into an individual valuation which in turn can be ranked in terms of preference (therefore intertemporal preferences). </p>

<p>The free parameter that is utilized to describe individual differences in intertemporal discounting is the k value in the above function (alpha in Chabris and Laibson (2008)<sup id="fnref:1:1"><a href="#fn:1" class="footnote">1</a></sup>). </p>

<p>This parameter is usually fit using choice data, which stems from binary decisions over reward-delay combinations. The basic experimental design to extract such choices is to expose experimental subjects to a series of decision screens (or pen-and-paper questionnaire) in which they are asked to decide over a series of two option choice-sets that involve a small immediate reward (SIR) and a large delayed reward (LDR). The delays and absolute amounts of the rewards are varied so that a broad picture on the intertemporal preferences of the individual subject can be extracted from the decisions taken.</p>

<p>In this case we opt for the Kirby (1997) intertemporal discounting questionnaire, which may be extended for more precision of the k-value estimates.</p>

<h3 id="the-data-set">The Data Set</h3>

<p>Following the experimental design outlined above, we end up with a data set that contains a decision for either the SIR or LDR (defined above), for each binary choice set. Decisions for the SIR are coded as 0 and decisions for the LDR are coded as 1.  </p>

<h3 id="fitting-the-likelihood-function">Fitting the likelihood function</h3>

<p>Given our data set we can proceed to estimate the k-value that describes our subject’s set of choices best. We do this by systematically inserting k’s into the function and solving for the respective likelihood of observing our choice data. We then systematically try different k-values to find the one which maximizes the this likelihood (In reality, given programming conventions, we take the the negative of this likelihood in order to solve a <em>minimization</em> problem). Note the underlying logic. We are trying to find the parameter values that is <em>most likely to generate the observed choice data</em>. We quantify the goodness of fit (lack of fit) as follows. Given any particular k we calculate the probability that at a particular choice screen, an agent who behaves according to our currently tested k, would have chosen as the experimental subject did. We take the negative log of this probability. We do this for all choice-screens and sum the negative log likelihoods to end up with a final likelihood for a given k. Now we search the space of k’s to find the best fitting k.</p>

<h3 id="issues">Issues</h3>

<p>Two things need to be noted for completeness. First, there is a certain precision associated with any set of questions that form the intertemporal choice questionnaire. So it is possible that agents who actually possess differing underlying k-values, end up chosing exactly the same options, simply because the difference in k-values is so small that the current set of questions is not able to distinguish them behaviorally. It is helpful here, to ask more than the standard 27 questions included in the Kirby (1997) questionnaire. Second, following the model of Chabris and Laibson (2008)<sup id="fnref:1:2"><a href="#fn:1" class="footnote">1</a></sup>, we are assuming that an agent has preference shocks following a logit function. Chabris and Laibson (2008)<sup id="fnref:1:3"><a href="#fn:1" class="footnote">1</a></sup> mention that their set of equations assumes <em>unit variance</em>, an assumptino which we carry on here. Potentially, the variance implicit in the logit function can be taken as a second degree of freedom in the model. </p>

<h2 id="coding-step-by-step">Coding: Step by step</h2>

<p>So far we outlined the basic logic of our fitting procedure. In what follows I will carry you through the necessary coding steps to derive a best fitting k, given some choice data. </p>

<h3 id="basics">Basics</h3>

<h4 id="reading-in-the-questionnaire-data">Reading in the questionnaire data</h4>

<p>In the following we assume that a csv-file (“kirby.csv”) with the following columns is in our working directory. </p>

<ol>
  <li>Order: A column that stores the order of questions asked  </li>
  <li>SIR: Column storing the small immediate rewards by choice set</li>
  <li>LDR: Column storing the large delayed rewards by choice set</li>
  <li>Delay: Column storing the respecitve delays for LDR’s</li>
</ol>

<p>We go ahead an read in the csv file.</p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="n">qdat</span> <span class="p">=</span> <span class="n">readtable</span><span class="p">(</span><span class="s">&#39;kirby.csv&#39;</span><span class="p">);</span></code></pre></div>

<h4 id="simulating-some-choices">Simulating some choices</h4>

<p>Next we are going to simulate some choices, according to some agent that behaves strictly according to our hyperbolic discounting function given some arbitrary k.</p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="c">% len is the length of the choice vector (number of choices to be</span>
  <span class="c">% predicted)</span>
  <span class="n">len</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">qdat</span><span class="p">.</span><span class="n">LDR</span><span class="p">);</span>

  <span class="c">% We define a new column in qdat that provides the simulated choices </span>
  <span class="c">% 0 represents the immediate reward</span>
  <span class="c">% 1 represents the delayed reward</span>
  <span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="n">len</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
  <span class="k">for</span> <span class="nb">i</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">len</span>
     <span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="n">SimulateChoice</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">qdat</span><span class="p">.</span><span class="n">SIR</span><span class="p">(</span><span class="nb">i</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">LDR</span><span class="p">(</span><span class="nb">i</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">Delay</span><span class="p">(</span><span class="nb">i</span><span class="p">));</span>
  <span class="k">end</span></code></pre></div>

<p>Let’s take a look what exactly happens in the SimulateChoice function. As you can see below,
we follow the simple decision rule that is outlined by Chabris and Laibson (2008)<sup id="fnref:1:4"><a href="#fn:1" class="footnote">1</a></sup>. An agent will only chose the delayed reward if the following condition holds true.</p>

<p><cite> Y / (1 + k*t) - X &gt;= 0 </cite></p>

<p>If the discounted value of the delayed reward is equal or above the imediate reward in the same choice set, we choose the delayed reward (coded as 1). Otherwise we chose the immediate reward (coded as 0).</p>

<p>The function needs as inputs,</p>

<ol>
  <li>the k according to which our simulated agent takes the decisions</li>
  <li>the SIR of the respective choice set</li>
  <li>the LDR of the respective choice set</li>
  <li>the delay associated with the LDR of the specific choice set</li>
</ol>

<p>We get back a choice output which is either 0 or 1 as specified above.</p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="k">function</span><span class="w"> </span>choice <span class="p">=</span><span class="w"> </span><span class="nf">SimulateChoice</span><span class="p">(</span>k,sir,ldr,delay<span class="p">)</span><span class="w"></span>
<span class="c">% Not used for now</span>
<span class="c">%p = exp(ldr/(1 + k*delay)) / (exp(sir) + exp(ldr/(1 + k*delay)));</span>

<span class="c">% By Chabris/Laibson 2008</span>
<span class="c">% If the right hand side is above 0 we choose the LDR (large delayed</span>
<span class="c">% reward) // coded as 1</span>
<span class="c">% IF the left hand is is below  0 we choose the SIR (small immediate</span>
<span class="c">% reward) // coded as 0</span>
 <span class="n">value</span> <span class="p">=</span>  <span class="p">(</span><span class="n">ldr</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">k</span><span class="o">*</span><span class="n">delay</span><span class="p">))</span> <span class="o">-</span> <span class="n">sir</span><span class="p">;</span> 
    <span class="k">if</span> <span class="p">(</span><span class="n">value</span> <span class="o">&gt;</span><span class="p">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">choice</span> <span class="p">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="k">else</span>
        <span class="n">choice</span> <span class="p">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">end</span>
<span class="k">end</span></code></pre></div>

<p>Note that the simulations are simplified, in the sense that, as will be clearer below, we skip any notion of logit distribution for the simulations. In case we assume that expressed preferences stem from a logit distribution, we end up with non binary choice probabilities (any value between 0 and 1) which would change the likelihood fitting procedure.</p>

<p>As our real data will come in form of binary (either 0 or 1) coding, using our approach to simulate choices makes the code down the line directly applicable to real choice data.</p>

<p>Note however, that without further explanation, our way of simulating choices here has the effect that our k’s as solutions to our minimization problem may not (in our case actually will not) match the k used to generate our data exactly.</p>

<h4 id="given-choices-estimate-loglikelihood-for-any-k">Given Choices, estimate LogLikelihood for any k</h4>

<p>Now that we have a bunch of choices, we can try to find the hyperbolic discounting function that fits these choices best. We do this by varying the k-value of the discounting function until we find a global minimium in the negative loglikelihood function.
Lets assume we have a function that takes in as parameters,</p>

<ol>
  <li>The set of real choices</li>
  <li>The associated SIR’s, LDR’s and delays</li>
  <li>The k-value we want to try as a choice of parameter</li>
</ol>

<p>As an output we will get a single number, which is the likelihood. Lets call the function <em>GenerateLogLik</em> and treat it as a blackbox for now. Such a function is also commonly called an <em>objective or loss function</em> and our goal is it to minimize its output value. </p>

<p>We could try out a bunch of k-values by hand, however <em>Matlab</em> offers us the <em>fminbnd() function</em> which will vary the k-value outomatically for us to find the optimal k. We just provie a <em>maximum and minimum k</em> to be tested and the rest will be taken care of. The function will provide us with two output numbers. </p>

<ol>
  <li>The optimal k-value (parameter value that minimized current loss function)</li>
  <li>The value of the loss function at optimal k</li>
</ol>

<p>The corresponding code looks like this.</p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="c">% Run minimization to find k-value</span>
  <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="p">=</span> <span class="n">fminbnd</span><span class="p">(@</span><span class="n">GenerateLogLik</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span></code></pre></div>

<p>Now lets take a look at what happens in the <em>GenerateLogLik()</em> function. Note that within the function, we refer to <em>struct qdat</em> which is where we stored our questionnaire and choice data earlier. We assume that this struct is assigned as a <em>globally accessable variable</em>. I will show the full script further below so that the connection of all the code snippets becomes clearer.</p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="k">function</span><span class="w"> </span>sumloglik <span class="p">=</span><span class="w"> </span><span class="nf">GenerateLogLik</span><span class="p">(</span>cur_k<span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="c">% Define vector that will store the probability that the model chooses</span>
    <span class="c">% as the participant for every choice</span>
   <span class="n">choiceprobabilities</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">length</span><span class="p">(</span><span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span><span class="p">),</span><span class="mi">1</span><span class="p">);</span>
   
   <span class="k">for</span> <span class="nb">j</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">len</span>
       <span class="c">% load the choice probability vector for every choice</span>
    <span class="n">choiceprobabilities</span><span class="p">(</span><span class="nb">j</span><span class="p">)</span> <span class="p">=</span> <span class="n">GetPChoice</span><span class="p">(</span><span class="n">cur_k</span><span class="p">,</span><span class="n">qdat</span><span class="p">.</span><span class="n">SIR</span><span class="p">(</span><span class="nb">j</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">LDR</span><span class="p">(</span><span class="nb">j</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">Delay</span><span class="p">(</span><span class="nb">j</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span><span class="p">(</span><span class="nb">j</span><span class="p">));</span>
   <span class="k">end</span>
   
   <span class="c">% take sum of logs and negative to be able to work within minimization</span>
   <span class="c">% framework</span>
   <span class="n">sumloglik</span> <span class="p">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="nb">log</span><span class="p">(</span><span class="n">choiceprobabilities</span><span class="p">)));</span>
<span class="k">end</span></code></pre></div>

<h4 id="putting-everything-together">Putting everything together</h4>

<p>Once, all of what we discussed before as one function <em>findK()</em></p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="c">% Provided a certain k for simulating choices, this function return the k</span>
<span class="c">% that minimizes errors for subjects that have preferences according to a</span>
<span class="c">% logit destribution with unit variance</span>

<span class="k">function</span><span class="w"> </span>[x,y] <span class="p">=</span><span class="w"> </span><span class="nf">findK</span><span class="p">(</span>k<span class="p">)</span><span class="w"></span>
<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%</span>
<span class="c">% READING IN DATA %%%%%%%</span>
<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%</span>

<span class="c">% Initialize Questionnaire Data</span>
<span class="c">% Four columns:</span>
<span class="c">% 1. Order </span>
<span class="c">% 2. SIR (small immediate reward) </span>
<span class="c">% 3. LDR (large delayed reward) </span>
<span class="c">% 4. Delay</span>
<span class="n">qdat</span> <span class="p">=</span> <span class="n">readtable</span><span class="p">(</span><span class="s">&#39;kirby.csv&#39;</span><span class="p">);</span>

<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>
<span class="c">% SIMULATING CHOICES FOR GIVEN K     %</span>
<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>

<span class="c">% Generate / Simulate a vector of decisions for given choice set</span>
<span class="c">% Simplest version:</span>
<span class="c">% Solve Y / (1+k*time) - X &gt;= 0 ? if bigger 0 than choose delayed</span>
<span class="c">% otherwise immediate</span>

<span class="c">% len is the length of the choice vector (number of choices to be</span>
<span class="c">% predicted)</span>
<span class="n">len</span> <span class="p">=</span> <span class="nb">length</span><span class="p">(</span><span class="n">qdat</span><span class="p">.</span><span class="n">LDR</span><span class="p">);</span>

<span class="c">% We define a new column in qdat that provides the simulated choices </span>
<span class="c">% 0 represents the immediate reward</span>
<span class="c">% 1 represents the delayed reward</span>
<span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="n">len</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
<span class="k">for</span> <span class="nb">i</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">len</span>
   <span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span><span class="p">(</span><span class="nb">i</span><span class="p">)</span> <span class="p">=</span> <span class="n">SimulateChoice</span><span class="p">(</span><span class="n">k</span><span class="p">,</span><span class="n">qdat</span><span class="p">.</span><span class="n">SIR</span><span class="p">(</span><span class="nb">i</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">LDR</span><span class="p">(</span><span class="nb">i</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">Delay</span><span class="p">(</span><span class="nb">i</span><span class="p">));</span>
<span class="k">end</span>

<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>
<span class="c">%     DEFINE OBJECTIVE FUNCTION         %</span>
<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>

<span class="k">function</span><span class="w"> </span>sumloglik <span class="p">=</span><span class="w"> </span><span class="nf">GenerateLogLik</span><span class="p">(</span>cur_k<span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="c">% Define vector that will store the probability that the model chooses</span>
    <span class="c">% as the participant for every choice</span>
   <span class="n">choiceprobabilities</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">length</span><span class="p">(</span><span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span><span class="p">),</span><span class="mi">1</span><span class="p">);</span>
   
   <span class="k">for</span> <span class="nb">j</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="n">len</span>
       <span class="c">% load the choice probability vector for every choice</span>
    <span class="n">choiceprobabilities</span><span class="p">(</span><span class="nb">j</span><span class="p">)</span> <span class="p">=</span> <span class="n">GetPChoice</span><span class="p">(</span><span class="n">cur_k</span><span class="p">,</span><span class="n">qdat</span><span class="p">.</span><span class="n">SIR</span><span class="p">(</span><span class="nb">j</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">LDR</span><span class="p">(</span><span class="nb">j</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">Delay</span><span class="p">(</span><span class="nb">j</span><span class="p">),</span><span class="n">qdat</span><span class="p">.</span><span class="n">Choices</span><span class="p">(</span><span class="nb">j</span><span class="p">));</span>
   <span class="k">end</span>
   
   <span class="c">% take sum of logs and negative to be able to work within minimization</span>
   <span class="c">% framework</span>
   <span class="n">sumloglik</span> <span class="p">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">sum</span><span class="p">(</span><span class="nb">log</span><span class="p">(</span><span class="n">choiceprobabilities</span><span class="p">)));</span>
<span class="k">end</span>

<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>
<span class="c">% RECOVER K WHEN HAVING SET OF CHOICES %</span>
<span class="c">%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%</span>

<span class="c">% Run minimization to find k-value</span>
<span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="p">=</span> <span class="n">fminbnd</span><span class="p">(@</span><span class="n">GenerateLogLik</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>
<span class="k">end</span></code></pre></div>

<h3 id="further-notes-on-k-precision">Further notes on k-precision</h3>

<p>Now that we know how to estimate the optimal k-value for a given choice data set, we can follow up with some further considerations on the realtionship between the questionnaire utilized and the precision of the optimal k-values, given binary choice data.
The following code snippet uses the function <em>findK()</em> defined above and plots the optimal k-values found, as a function of the k-values used to simulate the choice set. </p>

<div class="highlight"><pre><code class="language-matlab" data-lang="matlab"><span class="n">ks</span> <span class="p">=</span> <span class="mf">0.001</span><span class="p">:</span><span class="mf">0.001</span><span class="p">:</span><span class="mf">0.03</span><span class="p">;</span>
<span class="n">optimk</span> <span class="p">=</span> <span class="nb">zeros</span><span class="p">(</span><span class="nb">length</span><span class="p">(</span><span class="n">ks</span><span class="p">),</span><span class="mi">1</span><span class="p">);</span>

<span class="k">for</span> <span class="n">k</span> <span class="p">=</span> <span class="mi">1</span><span class="p">:</span><span class="nb">length</span><span class="p">(</span><span class="n">ks</span><span class="p">)</span>
    <span class="n">optimk</span><span class="p">(</span><span class="n">k</span><span class="p">)</span> <span class="p">=</span> <span class="n">findK</span><span class="p">(</span><span class="n">ks</span><span class="p">(</span><span class="n">k</span><span class="p">));</span>
<span class="k">end</span>

<span class="n">plot</span><span class="p">(</span><span class="n">ks</span><span class="p">,</span><span class="n">optimk</span><span class="p">)</span></code></pre></div>

<p>Looking at the graph that this script produces, note that it follows what looks like a step function. This illustrates the insensitivity of the simple 27 item Kirby (1997) questionnaire, to small changes in k-values. </p>

<p><img src="http://AlexanderFengler.github.io/blog_images/2015-02-07-K-Estimation/kfitted_vs_simulated.png" alt="kfitted_vs_simulated" /></p>

<p>Another way to show this, is by simply looking at the generated choices when simulating with varying k-values. It can easily be seen that small changes in k simply do not change any choice in the set and therefore will be treated as stemming from an equivalent agent when we try to find the best fitting k with our likelihood method.</p>

<p>Changing the underlying questionnaire will have an impact on this sensitivity.</p>

<h3 id="where-to-find-all-the-codehttpsgithubcomalexanderfenglerhyperbolicdiscountingmatlab">Where to find all the <a href="https://github.com/AlexanderFengler/hyperbolic_discounting_Matlab">code</a>?</h3>
<p>All code is uploaded <a href="https://github.com/AlexanderFengler/hyperbolic_discounting_Matlab"><em>here</em></a>. You can simply download the folder and add it to your path in Matlab.</p>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p><a href="http://www.nber.org/papers/w14270.pdf">Chabris C., Laibson D. (2008). Individual laboratory-measured discount rates predict field behavior. <em>J Risk Uncertain</em>, <em>37</em>,237-269</a> <a href="#fnref:1" class="reversefootnote">&#8617;</a> <a href="#fnref:1:1" class="reversefootnote">&#8617;<sup>2</sup></a> <a href="#fnref:1:2" class="reversefootnote">&#8617;<sup>3</sup></a> <a href="#fnref:1:3" class="reversefootnote">&#8617;<sup>4</sup></a> <a href="#fnref:1:4" class="reversefootnote">&#8617;<sup>5</sup></a></p>
    </li>
  </ol>
</div>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="http://AlexanderFengler.github.io/neuroeconomics/DDM-Timestep-Noise-Behavior/" class="btn" title="DDM: Does timestep size affect noise parameter?">Previous</a>
      
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<span>&copy; 2015 Alexander Fengler. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> using the <a href="http://mademistakes.com/so-simple/" rel="nofollow">So Simple Theme</a>.</span>
<div class="social-icons">
	<a href="http://twitter.com/UniFersAlex" title="Alexander Fengler on Twitter" target="_blank"><i class="fa fa-twitter-square fa-2x"></i></a>
	<a href="http://facebook.com/AlexanderFengler" title="Alexander Fengler on Facebook" target="_blank"><i class="fa fa-facebook-square fa-2x"></i></a>
	
	
	<a href="Affaeng" title="Alexander Fengler on StackExchange" target="_blank"><i class="fa fa-stack-exchange fa-2x"></i></a>
	
	
	<a href="http://github.com/Alexander Fengler" title="Alexander Fengler on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
	
  <a href="http://AlexanderFengler.github.io/feed.xml" title="Atom/RSS feed"><i class="fa fa-rss-square fa-2x"></i></a>
</div><!-- /.social-icons -->
  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://AlexanderFengler.github.io';
</script>

<script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://AlexanderFengler.github.io/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://AlexanderFengler.github.io/assets/js/scripts.min.js"></script>


	        

</body>
</html>
